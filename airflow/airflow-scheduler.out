[[34m2025-10-30T07:11:10.680+0000[0m] {[34mscheduler_job_runner.py:[0m788} INFO[0m - Starting the scheduler[0m
[[34m2025-10-30T07:11:10.748+0000[0m] {[34mscheduler_job_runner.py:[0m795} INFO[0m - Processing each file at most -1 times[0m
[[34m2025-10-30T07:11:10.754+0000[0m] {[34mmanager.py:[0m165} INFO[0m - Launched DagFileProcessorManager with pid: 2121[0m
[[34m2025-10-30T07:11:10.756+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2025-10-30T07:11:10.759+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone Timezone('UTC')[0m
[[34m2025-10-30T07:11:10.774+0000[0m] {[34mscheduler_job_runner.py:[0m1576} INFO[0m - Marked 1 SchedulerJob instances as failed[0m
[2025-10-30T07:11:10.785+0000] {manager.py:411} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2025-10-30T07:16:10.845+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2025-10-30T07:17:17.274+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.extract_task manual__2025-10-30T07:17:15.406317+00:00 [scheduled]>[0m
[[34m2025-10-30T07:17:17.274+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2025-10-30T07:17:17.274+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.extract_task manual__2025-10-30T07:17:15.406317+00:00 [scheduled]>[0m
[[34m2025-10-30T07:17:17.276+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='extract_task', run_id='manual__2025-10-30T07:17:15.406317+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2025-10-30T07:17:17.276+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2025-10-30T07:17:15.406317+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2025-10-30T07:17:17.280+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'extract_task', 'manual__2025-10-30T07:17:15.406317+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2025-10-30T07:17:18.048+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2025-10-30T07:17:18.818+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: challenge_dag.extract_task manual__2025-10-30T07:17:15.406317+00:00 [queued]> on host codespaces-497b64[0m
[[34m2025-10-30T07:17:20.353+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='challenge_dag', task_id='extract_task', run_id='manual__2025-10-30T07:17:15.406317+00:00', try_number=1, map_index=-1)[0m
[[34m2025-10-30T07:17:20.358+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=extract_task, run_id=manual__2025-10-30T07:17:15.406317+00:00, map_index=-1, run_start_date=2025-10-30 07:17:18.854787+00:00, run_end_date=2025-10-30 07:17:19.955099+00:00, run_duration=1.100312, state=success, executor_state=success, try_number=1, max_tries=0, job_id=21, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-10-30 07:17:17.275136+00:00, queued_by_job_id=20, pid=4478[0m
[[34m2025-10-30T07:17:20.399+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.transform_task manual__2025-10-30T07:17:15.406317+00:00 [scheduled]>[0m
[[34m2025-10-30T07:17:20.400+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2025-10-30T07:17:20.400+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.transform_task manual__2025-10-30T07:17:15.406317+00:00 [scheduled]>[0m
[[34m2025-10-30T07:17:20.401+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='transform_task', run_id='manual__2025-10-30T07:17:15.406317+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-10-30T07:17:20.401+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2025-10-30T07:17:15.406317+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2025-10-30T07:17:20.405+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'transform_task', 'manual__2025-10-30T07:17:15.406317+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2025-10-30T07:17:21.185+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2025-10-30T07:17:22.057+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: challenge_dag.transform_task manual__2025-10-30T07:17:15.406317+00:00 [queued]> on host codespaces-497b64[0m
[[34m2025-10-30T07:17:22.740+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='challenge_dag', task_id='transform_task', run_id='manual__2025-10-30T07:17:15.406317+00:00', try_number=1, map_index=-1)[0m
[[34m2025-10-30T07:17:22.743+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=transform_task, run_id=manual__2025-10-30T07:17:15.406317+00:00, map_index=-1, run_start_date=2025-10-30 07:17:22.114010+00:00, run_end_date=2025-10-30 07:17:22.381841+00:00, run_duration=0.267831, state=success, executor_state=success, try_number=1, max_tries=0, job_id=22, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-30 07:17:20.400818+00:00, queued_by_job_id=20, pid=4504[0m
[[34m2025-10-30T07:17:22.776+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: challenge_dag.load_task manual__2025-10-30T07:17:15.406317+00:00 [scheduled]>[0m
[[34m2025-10-30T07:17:22.777+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG challenge_dag has 0/16 running and queued tasks[0m
[[34m2025-10-30T07:17:22.777+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: challenge_dag.load_task manual__2025-10-30T07:17:15.406317+00:00 [scheduled]>[0m
[[34m2025-10-30T07:17:22.778+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='challenge_dag', task_id='load_task', run_id='manual__2025-10-30T07:17:15.406317+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2025-10-30T07:17:22.778+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'challenge_dag', 'load_task', 'manual__2025-10-30T07:17:15.406317+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2025-10-30T07:17:22.782+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'challenge_dag', 'load_task', 'manual__2025-10-30T07:17:15.406317+00:00', '--local', '--subdir', 'DAGS_FOLDER/challenge_dag.py'][0m
[[34m2025-10-30T07:17:23.561+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/challenge_dag.py[0m
[[34m2025-10-30T07:17:24.404+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: challenge_dag.load_task manual__2025-10-30T07:17:15.406317+00:00 [queued]> on host codespaces-497b64[0m
[[34m2025-10-30T07:17:25.107+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='challenge_dag', task_id='load_task', run_id='manual__2025-10-30T07:17:15.406317+00:00', try_number=1, map_index=-1)[0m
[[34m2025-10-30T07:17:25.111+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=challenge_dag, task_id=load_task, run_id=manual__2025-10-30T07:17:15.406317+00:00, map_index=-1, run_start_date=2025-10-30 07:17:24.441055+00:00, run_end_date=2025-10-30 07:17:24.757139+00:00, run_duration=0.316084, state=success, executor_state=success, try_number=1, max_tries=0, job_id=23, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-10-30 07:17:22.777607+00:00, queued_by_job_id=20, pid=4521[0m
[[34m2025-10-30T07:17:25.244+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun challenge_dag @ 2025-10-30 07:17:15.406317+00:00: manual__2025-10-30T07:17:15.406317+00:00, state:running, queued_at: 2025-10-30 07:17:15.417544+00:00. externally triggered: True> successful[0m
[[34m2025-10-30T07:17:25.245+0000[0m] {[34mdagrun.py:[0m681} INFO[0m - DagRun Finished: dag_id=challenge_dag, execution_date=2025-10-30 07:17:15.406317+00:00, run_id=manual__2025-10-30T07:17:15.406317+00:00, run_start_date=2025-10-30 07:17:17.245435+00:00, run_end_date=2025-10-30 07:17:25.245371+00:00, run_duration=7.999936, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-30 07:17:15.406317+00:00, data_interval_end=2025-10-30 07:17:15.406317+00:00, dag_hash=b6c7884bad6b52a4a8628a0b0e0fc044[0m
[[34m2025-10-30T07:21:10.884+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2025-10-30T07:26:10.925+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2025-10-30T07:31:11.222+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2025-10-30T07:36:11.253+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2025-10-30T07:41:11.281+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2025-10-30T07:46:11.308+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2025-10-30T07:51:11.335+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2025-10-30T07:56:11.363+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
